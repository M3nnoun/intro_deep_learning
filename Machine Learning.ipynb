{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An introduction to\n",
    "\n",
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is machine learning?\n",
    "\n",
    "- Machine learning (ML) is a techinque which uses computers to discover patterns or information about your data.\n",
    "- It is a part of the wider field of *artificial intelligence*\n",
    "- There are lots of different types of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples of machine learning\n",
    "\n",
    "- Simplest ML algorithm could be a linear regression. It automatically and iteratively looks at your data to calculate the parameters of your $y = mx + c$ curve\n",
    "- A more advenced technique is *K-means clustering*. It is a way of finding clusters of points in your data without having to input any explicit labels.\n",
    "- The most famous is *neural networks* (NN) which were inspired by the brain and use a directed network of connected neurons to describe features of the data set.\n",
    "    - More recently (since about 2010) *deep neural networks* (DNN) have become possible, allowing more detailed models of data to be learned starting the modern buzz for *deep learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What are neural networks\n",
    "\n",
    "Neural networks are a collection of artificial neurons connected together so it's best to start by learning about about neurons.\n",
    "\n",
    "In nature, a neuron is a cell which has an electrical connection to other neurons. If a charge is felt from 'enough' of the input neurons then the neuron fires and passes a charge to its output. This design and how they are arranged into networks is the direct inspiration for artificial neural networks.\n",
    "\n",
    "An artificial neuron has multiple inputs and can pass its output to multiple other neurons.\n",
    "\n",
    "A neuron will calculate its value, $p = \\sum_i{x_iw_i}$ where $x_i$ is the input value and $w_i$ is a weight assigned to that connection. This $p$ is then passed through some *activation function* to determine the output of the neuron.\n",
    "\n",
    "<img src=\"neuron.png\" alt=\"An artificial neuron\" style=\"width: 200px; margin:0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Networks\n",
    "\n",
    "The inputs to each neurons either come from the outputs of other neurons or are explicit inputs from the user. This allows you to connect together a large network of neurons:\n",
    "\n",
    "<img src=\"network.png\" alt=\"An artificial neural network\" style=\"width: 400px; margin:0 auto;\"/>\n",
    "\n",
    "In this network every neuron on one layer is connected to every neuron on the next. Every arrow in the diagram has a weight assigned to it.\n",
    "\n",
    "You input values on the left-hand side of the network, and the data flows through the network from layer to layer until the output layer has a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What shape should the network be?\n",
    "\n",
    "There is some art and some science to deciding the shape of a network. There are rules of thumb (hidden layer size should be similar sized to the input and output layers) but this is one of the things that you need to experiment with and see how it affects performance.\n",
    "\n",
    "The number of hidden layers relates to the level of abstraction you are looking at. Generally, more complex problems need more hidden layers (i.e. deeper networks) but this makes training harder.\n",
    "\n",
    "## How are the weights calculated?\n",
    "\n",
    "The calculation of the weights in a network is done through a process called *training*. This generally uses lots of data examples to iteratively work out good values for the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do you train neural networks\n",
    "\n",
    "The main method by which NNs are trained is a technique called *backpropogation*.\n",
    "\n",
    "In order to train your network you need a few things:\n",
    " - A labelled training data set\n",
    " - A labelled test (or evaluation) data set\n",
    " - A set of initial weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Initial weights\n",
    "\n",
    "The weights to start with are easy: just set them randomly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training and testing data sets\n",
    "\n",
    "You will need two data sets. One will be used by the learning algorithm to train the network and the other will be used to report on the quality of the training at the end.\n",
    "\n",
    "It is important that these data sets are disjoint to prevent *overfitting*.\n",
    "\n",
    "It is common to start with one large set of data that you want to learn about and to split it into 80% training data set and 20% test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Backpropogation (\"the backward propogation of errors\")\n",
    "\n",
    "Once you have your network structure, your initial weights and your training data set, you can start training.\n",
    "\n",
    "There have been lots of algorithms to do this over the last several decades but the currently most popular one is *backpropogation*.\n",
    "\n",
    "The first thing you need to do is to calculate the derivative of each weight with respect to the output of the network, $D_n = \\frac{dw_n}{dy}$. This gives how much you need to tweak each weight—and in which direction—to correct the output.\n",
    "\n",
    "Then for each training entry:\n",
    " - pass it through the network and find the value $y$\n",
    " - compare $y$ with the expected true output, $t$ to calculate the error $\\epsilon$\n",
    " - tweak each weight by $\\delta w_n = \\epsilon R \\frac{dw_n}{dy}$ where $R$ is the *learning rate*\n",
    " \n",
    "This means that the 'more wrong' the weights are, the more the move towards the true value. This slows down as, after lots of examples, the network *converges*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"backprop1.png\" alt=\"Back propogation example\" style=\"width: 100%; margin:0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common neural network libraries\n",
    "\n",
    "It would, as with with most things, be possible to to the above by hand but that would take years to make any progress. Instead we use software packages to do the leg work for us.\n",
    "\n",
    "The can in general, construct networks, automatically calculate derivatives, perform backpropogation and evaluate performance for you.\n",
    "\n",
    "Some of the most popular are:\n",
    "- PyTorch\n",
    "- TensorFlow\n",
    "- Keras\n",
    "- Caffe2\n",
    "- scikit-learn\n",
    "\n",
    "In this workshop, we will be using TensorFlow with a little bit of Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Our first neural network: classifying Irises\n",
    "\n",
    "We're going to start with a classic machine learning example, classifying species of Irises.\n",
    "\n",
    "![three iris species](iris_three_species.jpg)\n",
    "\n",
    "Iris setosa, Iris versicolor, and Iris virginica "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data set\n",
    "\n",
    "There [exists a data set of 150 irises](https://en.wikipedia.org/wiki/Iris_flower_data_set), each classified by sepal length and width, and petal length and width.\n",
    "\n",
    "|Sepal length |\tsepal width |\tpetal length |\tpetal width |\tspecies|\n",
    "|--- |\t--- |\t--- |\t--- |\t-|\n",
    "|6.4 |\t2.8 |\t5.6 |\t2.2 |\t2|\n",
    "|5.0 |\t2.3 |\t3.3 |\t1.0 |\t1|\n",
    "|0.9 |\t2.5 |\t4.5 |\t1.7 |\t2|\n",
    "|4.9 |\t3.1 |\t1.5 |\t0.1 |\t0|\n",
    "|... |\t... |\t... |\t... |\t...|\n",
    "\n",
    "Each species label is naturally a string (for example, \"setosa\"), but machine learning typically relies on numeric values. Therefore, someone mapped each string to a number. Here's the representation scheme:\n",
    "\n",
    " - 0 represents setosa\n",
    " - 1 represents versicolor\n",
    " - 2 represents virginica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"Iris_dataset_scatterplot.png\" alt=\"Iris data scatterplot\" style=\"width: 80%; margin:0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The code\n",
    "\n",
    "The Python code that we will be running is available at [premade_estimator.py](https://github.com/milliams/machine_learning/blob/master/premade_estimator.py). Feel free to follow along with that file but the important parts of the code will be on these slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loading our data\n",
    "\n",
    "Since we're working with a common data set, TensorFlow comes with some helper function to load the data into the correct form for us.\n",
    "\n",
    "In [iris_data.py](https://github.com/milliams/machine_learning/blob/master/iris_data.py), there is a function `load_data`.\n",
    "\n",
    "```python\n",
    ">>> (train_x, train_y), (test_x, test_y) = load_data()\n",
    ">>> train_x.head()\n",
    "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
    "0          6.4         2.8          5.6         2.2\n",
    "1          5.0         2.3          3.3         1.0\n",
    "2          4.9         2.5          4.5         1.7\n",
    "3          4.9         3.1          1.5         0.1\n",
    "4          5.7         3.8          1.7         0.3\n",
    ">>> train_y.head()\n",
    "0    2\n",
    "1    1\n",
    "2    2\n",
    "3    0\n",
    "4    0\n",
    "Name: Species, dtype: int64\n",
    "```\n",
    "It brings in the data from a CSV file into a Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Prepping our data\n",
    "\n",
    "Also in [iris_data.py](https://github.com/milliams/machine_learning/blob/master/iris_data.py) there is a function called `train_input_fn`:\n",
    "\n",
    "```python\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset\n",
    "```\n",
    "\n",
    "We pass this `train_x`, `train_y` and our wanted batch size.\n",
    "\n",
    " - First it converts the input data format to a TensorFlow `Dataset`\n",
    " - Then it shuffles, repeats and batches the examples\n",
    " - Finally it returns the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Designing our network\n",
    "\n",
    "TensorFlow comes with a network specially designed for this kind of *classification* problem. It automates a lot of the setup work but has a few configurable parameters.\n",
    "\n",
    "The network is called [tf.estimator.DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) (Deep Neural Network Classifier). In our case we will give it three things:\n",
    " 1. the list of the features (in our case 'SepalLength', 'SepalWidth', 'PetalLength' and 'PetalWidth')\n",
    " 2. the number and size of the hidden layers\n",
    " 3. the number of output classes to create\n",
    "\n",
    "```python\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[10, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3\n",
    ")\n",
    "```\n",
    "\n",
    "and that is all that is needed to describe the shape of our network. We can now get to work training it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training our network\n",
    "\n",
    "To train our network, all we need to do is call the `train` method on the classifier object we just created.\n",
    "\n",
    "It takes two arguments: the first is the function to use to generate the training data set so we use our `train_input_fn` from above and the second is the numer of steps to perform which will change how long it trains for.\n",
    "\n",
    "```python\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_x, train_y,\n",
    "                                             args.batch_size),\n",
    "    steps=args.train_steps\n",
    ")\n",
    "```\n",
    "\n",
    "At this point, TensorFlow will go ahead and train the network, outputting its progress to the screen. It should take a few seconds to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluating our model\n",
    "\n",
    "We want to check how good a job the training did so we then evaluate our network on our test data set. It takes a very similar form to training:\n",
    "\n",
    "```python\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(test_x, test_y,\n",
    "                                            args.batch_size))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "```\n",
    "\n",
    "It should print something like:\n",
    "\n",
    "```\n",
    "Test set accuracy: 0.933\n",
    "```\n",
    "\n",
    "telling us that the network classified the test data set with a 93.3% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Use the model\n",
    "\n",
    "Finally, we want to use the model to make a prediction about the real world. Given a few examples of irises, we evaluate them using the model and compare the results to what would expect:\n",
    "\n",
    "```python\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                            labels=None,\n",
    "                                            batch_size=args.batch_size))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Run it yourself\n",
    "\n",
    "Once you are logged onto BC4, you can run the iris neural network by typing\n",
    "\n",
    "```\n",
    "sbatch iris.slm\n",
    "```\n",
    "\n",
    "That will submit a processing job to the scheduling system and will hopefully start running it immediately. It will print a number to the screen which is the job number. Make a note of this. You can check the status of your job using `sacct -j 123456` (or whatever your job ID is).\n",
    "\n",
    "Once it is finished, you can check the output using `less slurm-123456.out`. Press page-down to scroll through the output and `q` to exit. At the end you should see:\n",
    "```\n",
    "Test set accuracy: 0.967\n",
    "\n",
    "Prediction is \"Setosa\" (99.8%), expected \"Setosa\"\n",
    "Prediction is \"Versicolor\" (99.6%), expected \"Versicolor\"\n",
    "Prediction is \"Virginica\" (98.5%), expected \"Virginica\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to image analysis\n",
    "\n",
    "The iris example worked well but the big downside is that it required manual processing of the real-world data before it could be modelled. Someone had to go with a ruler and measure the lengths and widths of each of the flowers. A more common and easily obtainable corpus is images.\n",
    "\n",
    "There have been many advancements in image analysis but at the core of most of them is *kernel convolution*. This starts by treating the image as a grid of numbers, where each number represents the brightness of the pixel\n",
    "\n",
    "$$\n",
    "\\begin{matrix} \n",
    "105 & 102 & 100 & 97 & 96 & \\dots \\\\\n",
    "103 & 99 & 103 & 101 & 102 & \\dots \\\\\n",
    "101 & 98 & 104 & 102 & 100 & \\dots \\\\\n",
    "99 & 101 & 106 & 104 & 99 & \\dots \\\\\n",
    "104 & 104 & 104 & 100 & 98 & \\dots \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots\n",
    "\\end{matrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Define a kernel\n",
    "\n",
    "You can then create a *kernel* which defines a filter to be applied to the image:\n",
    "\n",
    "$$\n",
    "Kernel = \\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 5 & -1 \\\\\n",
    "0 & -1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Depending on the values in the kernel, different filtering operations will be performed. The most common are:\n",
    "\n",
    " - sharpen (shown above)\n",
    " - blur\n",
    " - edge detection (directional or isotropic)\n",
    " \n",
    "The values of the kernels are created by mathematical analysis and are generally fixed. You can see some examples on the [Wikipedia page on kernels](https://en.wikipedia.org/wiki/Kernel_%28image_processing%29)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Applying a kernel\n",
    "\n",
    "This kernel is then overlaid over each set of pizels in the image, corresponding values are multiplied and then the total is summed:\n",
    "\n",
    "<img src=\"conv1.jpg\" alt=\"Convolution\" style=\"width: 600px; margin:0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## First pixel\n",
    "\n",
    "![Convolution](conv3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Second pixel\n",
    "\n",
    "![Convolution](conv4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with edges\n",
    "\n",
    "![Convolution](conv5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Before and after\n",
    "\n",
    "If using a Sobel edge detection kernel, you will see the following effect\n",
    "\n",
    "![Before and after](filter.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional neural networks\n",
    "\n",
    "At the core of convolutional neural networks (CNNs) is their ability to create abstract feature detectors automatically. If carefully combined, you can create a network which has layers of abstraction going from \"is there an edge here\" to \"is there an eye here\" to \"is this a person\".\n",
    "\n",
    "From a neural network perspective, there is little different in training. You can simply treat each element of the convolution kernel as a weight as we did before. The backpropogation algorithm will automatically learn the correct values to describe the training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "CNNs apply a series of filters to the raw pixel data of an image to extract and learn higher-level features, which the model can then use for classification. They usually contain three components:\n",
    "\n",
    " - *Convolutional layers*, which apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map.\n",
    " \n",
    " - *Pooling layers*, which downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. A commonly used pooling algorithm is *max pooling*, which extracts subregions of the feature map (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other values.\n",
    " \n",
    " - *Dense (fully connected) layers*, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical CNN\n",
    "\n",
    "![Typical CNN](typical_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Image segmentation\n",
    "\n",
    "![Mapillary](mapillary.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learn painting styles\n",
    "\n",
    "![Deep Painterly](deeppainterly.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Nature\n",
    "\n",
    "![cat](cat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Handwriting recognition\n",
    "\n",
    "The MNIST data set is a collection of 70,000 28×28 pixel images of scanned, handwritten digits.\n",
    "\n",
    "![MNIST examples](MnistExamples.png)\n",
    "\n",
    "We want to create a network which can, given a similar image of a digit, identify its value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using TensorFow to create and train a network\n",
    "\n",
    "In TensorFlow, there are three main tasks needed before you can start training. You must:\n",
    "\n",
    " 1. Specify the shape of your network\n",
    " 2. Specify how the network should be trained\n",
    " 3. Specify your training data set\n",
    " \n",
    "We will now go through each of these to show how the parts fit together.\n",
    "\n",
    "The code we are using is available at [mnist.py](https://github.com/milliams/machine_learning/blob/master/mnist.py) so feel free to have a peek but the important bits will be on these slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Designing the CNN\n",
    "\n",
    "We will create a network which fits the following design:\n",
    "\n",
    " 1. **Convolutional Layer #1**: Applies 32 5×5 filters (extracting 5×5-pixel subregions), with [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) activation function\n",
    " 2. **Pooling Layer #1**: Performs max pooling with a 2×2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    " 3. **Convolutional Layer #2**: Applies 64 5×5 filters, with ReLU activation function\n",
    " 4. **Pooling Layer #2**: Again, performs max pooling with a 2×2 filter and stride of 2\n",
    " 5. **Dense Layer #1**: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 40% that any given element will be dropped during training)\n",
    " 6. **Dense Layer #2 (Logits Layer)**: 10 neurons, one for each digit target class (0–9).\n",
    "\n",
    "This struture has been designed and tweaked specifically for the problem of classifying the MNIST data, however in general it is a good starting point for any similar image analysis problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Building the CNN\n",
    "\n",
    "We're using TensorFlow to create our CNN but we're able to use the Keras API inside it to simplify the network construction. We create a function, `create_model()`, which returns the definition of the network.\n",
    "\n",
    "### Reshaping the data\n",
    "\n",
    "The first things we need to do it tell TensorFlow about the shape of our images. The data it initially gets passed is simply a 784 element long list rather than a 28×28 2D array. The Keras `Reshape` object can do this reshaping:\n",
    "\n",
    "```python\n",
    "def create_model():\n",
    "    l = tf.keras.layers\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            l.Reshape(\n",
    "                target_shape=[1, 28, 28],\n",
    "                input_shape=(28 * 28,))\n",
    "        ]\n",
    "    )\n",
    "```\n",
    "\n",
    "There are still effectively 784 input values to the network, it's simply that TensorFlow now knows how they are arranged spatially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First convolutional layer\n",
    "\n",
    "We then add in our first convolutional layer. It create 32 5×5 filters. Since we have specified `padding='same'`, the size of the layer will still be 28×28 but as we specified 32 filters the overall size of the layer will be 28×28×32=25,088.\n",
    "\n",
    "```python\n",
    "def create_model():\n",
    "    l = tf.keras.layers\n",
    "\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            l.Reshape(\n",
    "                target_shape=[1, 28, 28],\n",
    "                input_shape=(28 * 28,)),\n",
    "            l.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=5,\n",
    "                padding='same',\n",
    "                activation=tf.nn.relu)\n",
    "        ]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First pooling layer\n",
    "\n",
    "Next we add in a pooling layer. This reduces the size of the image by a factor of two in each direction (now effectively a 14×14 pixel image). This is important to reduce memory usage and to allow feature generalisation.\n",
    "\n",
    "```python\n",
    "def create_model():\n",
    "    l = tf.keras.layers\n",
    "    max_pool = l.MaxPooling2D((2, 2), padding='same')\n",
    "\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            l.Reshape(\n",
    "                target_shape=[1, 28, 28],\n",
    "                input_shape=(28 * 28,)),\n",
    "            l.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=5,\n",
    "                padding='same',\n",
    "                activation=tf.nn.relu),\n",
    "            max_pool\n",
    "        ]\n",
    "    )\n",
    "```\n",
    "\n",
    "After pooling, the layer size is 14×14×32=6272."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Second convolutional and pooling layers\n",
    "\n",
    "We then add in our second convolution and pooling layers which reduce the image size while increasing the width of the network so we can describe more features:\n",
    "\n",
    "```python\n",
    "def create_model():\n",
    "    l = tf.keras.layers\n",
    "    max_pool = l.MaxPooling2D((2, 2), padding='same')\n",
    "\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            ...\n",
    "            max_pool,\n",
    "            l.Conv2D(\n",
    "                filters=64,\n",
    "                kernel_size=5,\n",
    "                padding='same',\n",
    "                activation=tf.nn.relu),\n",
    "            max_pool\n",
    "        ]\n",
    "    )\n",
    "```\n",
    "\n",
    "After this final convolution and pooling, we have a layer of size 7×7×64=3136."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fully-connected section\n",
    "\n",
    "Finally, we get to the fully-connected part of the network. At this point we no longer consider this an 'image' any more so we flatten our 3D layer into a linear set of nodes. We then add in a dense (fully-connected) layer with 1024 neurons.\n",
    "\n",
    "To avoid over-fitting, we apply *dropout regularization* to our dense layer which causes it to randomly ignore 40% of the nodes each training cycle (to help avoid overfitting) before adding in our final layer which has 10 neurons which we expect to relate to each of our 10 classifications:\n",
    "\n",
    "```python\n",
    "def create_model():\n",
    "    l = tf.keras.layers\n",
    "    max_pool = l.MaxPooling2D((2, 2), padding='same')\n",
    "\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            ...\n",
    "            l.Flatten(),\n",
    "            l.Dense(1024, activation=tf.nn.relu),\n",
    "            l.Dropout(0.4),\n",
    "            l.Dense(10)\n",
    "        ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Telling it how to train\n",
    "\n",
    "TensorFlow requires that we create a function which returns an `'EstimatorSpec'` which describes how the model should be trained. Here we specify which optimiser to use (ADAM is a slightly smarter gradient-descent algorithm) as well as our loss function (related to the error calculation we did earlier):\n",
    "\n",
    "```python\n",
    "def model_fn(image, labels, mode, params):\n",
    "    model = create_model()\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "    logits = model(image, training=True)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        loss=loss,\n",
    "        train_op=optimizer.minimize(loss,\n",
    "                                    tf.train.get_or_create_global_step())\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating the training data\n",
    "\n",
    "The final thing to do before we start training is to tell TensorFlow what training data to use. We create a function which grabs the data from disk (using [mnist_dataset.py](https://github.com/milliams/machine_learning/blob/master/mnist_dataset.py)), shuffles it and batches it up. It repeats the data a variable number of times (\"number of epochs\") before returning it.\n",
    "\n",
    "```python\n",
    "def train_input_fn():\n",
    "    ds = dataset.train(flags_obj.data_dir)\n",
    "    ds = ds.cache().shuffle(buffer_size=50000).batch(flags_obj.batch_size)\n",
    "\n",
    "    ds = ds.repeat(flags_obj.train_epochs)\n",
    "    return ds\n",
    "```\n",
    "\n",
    "To actually start training, we create an estimator which uses our `model_fn` defined above and call the `train()` method:\n",
    "\n",
    "```python\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=model_fn)\n",
    "\n",
    "mnist_classifier.train(input_fn=train_input_fn)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Run it yourself\n",
    "\n",
    "Like we did for the iris example, run:\n",
    "\n",
    "```\n",
    "sbatch mnist.slm\n",
    "```\n",
    "\n",
    "Again, it will print a number to the screen which is the job number. Make a note of this. You can check the status of your job using `sacct -j 123456` (or whatever your job ID is)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Now we wait...\n",
    "\n",
    "![Waiting](https://imgs.xkcd.com/comics/compiling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Check the output\n",
    "\n",
    "Once it is finished, you can check the output using `less slurm-123456.out`. Press page-down to scroll through the output and `q` to exit. At the end you should see something like:\n",
    "\n",
    "```\n",
    "Evaluation results:\n",
    "        {'accuracy': 0.9903, 'loss': 0.029199935, 'global_step': 6000}\n",
    "...\n",
    "dog. CNN thinks it's a 8 (65.2%)\n",
    "1 at 5.2. CNN thinks it's a 8 (80.1%)\n",
    "2 at 41.5. CNN thinks it's a 1 (55.3%)\n",
    "3 at 14.6. CNN thinks it's a 8 (71.9%)\n",
    "4 at 12.8. CNN thinks it's a 1 (85.7%)\n",
    "5 at 99.9. CNN thinks it's a 5 (99.9%)\n",
    "6 at 2.2. CNN thinks it's a 8 (86.3%)\n",
    "7 at 15.8. CNN thinks it's a 1 (71.8%)\n",
    "8 at 71.0. CNN thinks it's a 8 (71.0%)\n",
    "9 at 0.3. CNN thinks it's a 8 (57.0%)\n",
    "```\n",
    "\n",
    "Or, in a more useful table form..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table cellpadding=\"0\" style=\"border-collapse: collapse; border-style: hidden;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<td><b>Image</b></td>\n",
    "<td><b>0</b></td>\n",
    "<td><b>1</b></td>\n",
    "<td><b>2</b></td>\n",
    "<td><b>3</b></td>\n",
    "<td><b>4</b></td>\n",
    "<td><b>5</b></td>\n",
    "<td><b>6</b></td>\n",
    "<td><b>7</b></td>\n",
    "<td><b>8</b></td>\n",
    "<td><b>9</b></td>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><img src=\"1.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>1%</td>\n",
    "<td>28%</td>\n",
    "<td>17%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:red;\">53%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"2.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>1%</td>\n",
    "<td style=\"color:green;\">99%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"3.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>2%</td>\n",
    "<td>1%</td>\n",
    "<td style=\"color:red;\">61%</td>\n",
    "<td>26%</td>\n",
    "<td>1%</td>\n",
    "<td>2%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>7%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"4.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>33%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:red;\">52%</td>\n",
    "<td>14%</td>\n",
    "<td>1%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"5.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">100%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"6.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>2%</td>\n",
    "<td>0%</td>\n",
    "<td>5%</td>\n",
    "<td style=\"color:red;\">46%</td>\n",
    "<td>0%</td>\n",
    "<td>28%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>19%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"7.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>5%</td>\n",
    "<td>27%</td>\n",
    "<td style=\"color:red;\">41%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>21%</td>\n",
    "<td>5%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"8.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>1%</td>\n",
    "<td>1%</td>\n",
    "<td style=\"color:red;\">37%</td>\n",
    "<td>24%</td>\n",
    "<td>0%</td>\n",
    "<td>7%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>29%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"9.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>1%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:red;\">46%</td>\n",
    "<td>24%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>28%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"dog.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>15%</td>\n",
    "<td>19%</td>\n",
    "<td>0%</td>\n",
    "<td>1%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:red;\">65%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "`2` and `5` seem to have worked well but the rest are struggling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data augmentation\n",
    "\n",
    "The problem we're seeing here is caused by our training set being a bit restrictive. The network can only learn from what we show it so if we want it to be able to understand black-on-white writing as well as white-on-black then we need to show it some labelled examples of that too.\n",
    "\n",
    "If you're training your network to recognise dogs then you don't just want good-looking, well-lit photos of dogs straight on. You want to be able to recognise a variety of angles, lighting conditions, framings etc. Some of these can only be improved by supplying a wider range of input (e.g. by taking new photos) but you can go a long way to improving your resiliency to test data by automatically creating new examples by inverting, blurring, rotating, adding noise, scaling etc. your training data. This is known as *data augmentation*.\n",
    "\n",
    "In general, data augmentation is an important part of training any network but it is particularly useful for CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inverting the images\n",
    "\n",
    "In our case we're going to simply add colour-inverted versions of the data to our training data set.\n",
    "\n",
    "We use the `Dataset.map()` and `Dataset.concatenate()` methods to double up our training set with a set of images where all the values have been inverted in the range 0-1.\n",
    "\n",
    "```python\n",
    "def invert(image, label):\n",
    "    return (image * -1) + 1.0, label\n",
    "\n",
    "def train_input_fn():\n",
    "    ds = dataset.train(flags_obj.data_dir)\n",
    "\n",
    "    inverted = ds.map(invert)\n",
    "    ds = ds.concatenate(inverted)\n",
    "    \n",
    "    ds = ds.cache().shuffle(buffer_size=50000).batch(flags_obj.batch_size)\n",
    "    ds = ds.repeat(flags_obj.train_epochs)\n",
    "    return ds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Run it again\n",
    "\n",
    "Once more, submit a job to the scheduler with:\n",
    "\n",
    "```\n",
    "sbatch mnist_invert.slm\n",
    "```\n",
    "\n",
    "and check the output when it is done. You should see a significant improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table cellpadding=\"0\" style=\"border-collapse: collapse; border-style: hidden;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<td><b>Image</b></td>\n",
    "<td><b>0</b></td>\n",
    "<td><b>1</b></td>\n",
    "<td><b>2</b></td>\n",
    "<td><b>3</b></td>\n",
    "<td><b>4</b></td>\n",
    "<td><b>5</b></td>\n",
    "<td><b>6</b></td>\n",
    "<td><b>7</b></td>\n",
    "<td><b>8</b></td>\n",
    "<td><b>9</b></td>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><img src=\"1.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>10%</td>\n",
    "<td style=\"color:green;\">69%</td>\n",
    "<td>5%</td>\n",
    "<td>1%</td>\n",
    "<td>0%</td>\n",
    "<td>5%</td>\n",
    "<td>4%</td>\n",
    "<td>3%</td>\n",
    "<td>0%</td>\n",
    "<td>2%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"2.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">100%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"3.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">100%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"4.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">100%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"5.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">100%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"6.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">100%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"7.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>0%</td>\n",
    "<td>5%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">95%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"8.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>1%</td>\n",
    "<td>1%</td>\n",
    "<td>4%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td style=\"color:green;\">93%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"9.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td style=\"color:red;\">70%</td>\n",
    "<td>8%</td>\n",
    "<td>2%</td>\n",
    "<td>0%</td>\n",
    "<td>8%</td>\n",
    "<td>1%</td>\n",
    "<td>0%</td>\n",
    "<td>0%</td>\n",
    "<td>5%</td>\n",
    "<td>5%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"dog.png\" style=\"margin: 1px 0px\"></td>\n",
    "<td>2%</td>\n",
    "<td>26%</td>\n",
    "<td>20%</td>\n",
    "<td>4%</td>\n",
    "<td>3%</td>\n",
    "<td>7%</td>\n",
    "<td>4%</td>\n",
    "<td style=\"color:red;\">32%</td>\n",
    "<td>2%</td>\n",
    "<td>0%</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "It's possible that you only see a small improvement and even a worsening on some examples. Particularly on the `9` example, the network will struggle as it doesn't really represent the training data set. Here are some things that may improve network performance:\n",
    "\n",
    " - More data augmentation (brightness, rotations, blurring etc.)\n",
    " - Larger base training set (colour images perhaps)\n",
    " - Larger number of training epochs (in general, the more the better)\n",
    " - Tweak the hyperparameters (dropout rate, learning rate, kernel size, number of filters, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ethics of machine learning\n",
    "\n",
    "Machine learning has the problem that it can appear to be a bit of a 'black box' when processing information. You put in your question and you get out an answer. The answer isn't necessarilly correct and if you ask a stupid question (like \"what handwritten digit is this dog?\") you will still get an answer.\n",
    "\n",
    "Machine learning techniques are becoming more of a part of our daily lives, used by companies to make decisions but with no human in the loop, it can be hard to challenge. Google have a set of [AI principles](https://blog.google/technology/ai/ai-principles/) they work towards which I recommend reading but boil down to:\n",
    "\n",
    " 1. Be socially beneficial. \n",
    " 2. Avoid creating or reinforcing unfair bias.\n",
    " 3. Be built and tested for safety.\n",
    " 4. Be accountable to people.\n",
    " 5. Incorporate privacy design principles.\n",
    " 6. Uphold high standards of scientific excellence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Credits:\n",
    "\n",
    "- Dog photo: CC BY 2.0 [Emily Mathews](https://www.flickr.com/photos/eamathe/14517807267/)\n",
    "- Irises: <a href=\"https://commons.wikimedia.org/w/index.php?curid=170298\">Iris setosa</a> (by\n",
    "<a href=\"https://commons.wikimedia.org/wiki/User:Radomil\">Radomil</a>, CC BY-SA 3.0),\n",
    "<a href=\"https://commons.wikimedia.org/w/index.php?curid=248095\">Iris versicolor</a> (by\n",
    "<a href=\"https://commons.wikimedia.org/wiki/User:Dlanglois\">Dlanglois</a>, CC BY-SA 3.0),\n",
    "and <a href=\"https://www.flickr.com/photos/33397993@N05/3352169862\">Iris virginica</a>\n",
    "(by <a href=\"https://www.flickr.com/photos/33397993@N05\">Frank Mayfield</a>, CC BY-SA\n",
    "2.0).\n",
    "- Kernel convolution images: http://machinelearninguru.com/computer_vision/basics/convolution/image_convolution_1.html\n",
    "- CNN layout: CC BY-SA 4.0 [Aphex34](https://commons.wikimedia.org/wiki/File:Typical_cnn.png)\n",
    "- XKCD Compiling comic: CC BY-NC 2.5 [Randall Munroe](https://xkcd.com)\n",
    "- Image segmentation: Copyright [Mapillary](https://blog.mapillary.com/update/2018/01/11/new-benchmarks-for-semantic-segmentation-models.html)\n",
    "- Deep painterly: [Fujun Luan](https://github.com/luanfujun/deep-painterly-harmonization)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
